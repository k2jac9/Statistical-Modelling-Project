{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CityBikes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Third-Party Imports\n",
    "import folium\n",
    "import requests\n",
    "import pandas as pd\n",
    "from haversine import haversine, Unit\n",
    "from geopy.geocoders import Nominatim\n",
    "from pandas import json_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "API_BASE_URL = \"http://api.citybik.es/v2\"\n",
    "NETWORK_ID = 'velib'\n",
    "NETWORKS_PATH = '../data/raw_networks.csv'\n",
    "STATIONS_PATH = '../data/raw_stations.csv'\n",
    "\n",
    "# Function to fetch JSON data from a URL\n",
    "def fetch_json_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        content_type = response.headers.get('content-type', '').lower()\n",
    "        if 'application/json' in content_type:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Invalid content type: {content_type}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON response from {url}: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# Function to recursively collect all keys and their data types from a JSON-like object\n",
    "def get_all_keys_with_types(obj, keys_with_types, parent_key=''):\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            full_key = f\"{parent_key}.{key}\" if parent_key else key\n",
    "            keys_with_types[full_key] = type(value).__name__\n",
    "            get_all_keys_with_types(value, keys_with_types, full_key)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            get_all_keys_with_types(item, keys_with_types, parent_key)\n",
    "\n",
    "\n",
    "# Function to process network data and save to CSV\n",
    "def process_network_data(data):\n",
    "    if data:\n",
    "        all_keys_with_types = {}\n",
    "        get_all_keys_with_types(data, all_keys_with_types)\n",
    "\n",
    "        print(\"Keys and Types for {url}:\")\n",
    "        for key, data_type in sorted(all_keys_with_types.items()):\n",
    "            print(f\"{key}: {data_type}\")\n",
    "\n",
    "        total_networks = len(data.get(\"networks\", []))\n",
    "        print(f\"Total number of networks: {total_networks}\")\n",
    "\n",
    "        # Flatten the JSON data\n",
    "        flattened_data = []\n",
    "        for network in data.get(\"networks\", []):\n",
    "            # Flatten each network entry and append to the list\n",
    "            flattened_data.append(json_normalize(network))\n",
    "\n",
    "        # Concatenate all flattened data into a single DataFrame\n",
    "        df = pd.concat(flattened_data, ignore_index=True)\n",
    "\n",
    "        # Save station network to a CSV file\n",
    "        df.to_csv(NETWORKS_PATH, index=False)\n",
    "\n",
    "\n",
    "# Function to process station data\n",
    "def process_station_data(data):\n",
    "    if data:\n",
    "        all_keys_with_types = {}\n",
    "        get_all_keys_with_types(data, all_keys_with_types)\n",
    "\n",
    "        print(\"Keys and Types for {url}:\")\n",
    "        for key, data_type in sorted(all_keys_with_types.items()):\n",
    "            print(f\"{key}: {data_type}\")\n",
    "\n",
    "        # Extract station data from the JSON\n",
    "        station_data = data.get(\"network\", {}).get(\"stations\", [])\n",
    "        total_stations = len(station_data)\n",
    "        print(f\"Total number of stations: {total_stations}\")\n",
    "\n",
    "        # Flatten the JSON station data\n",
    "        flattened_data = []\n",
    "        for station in station_data:\n",
    "            flattened_data.append(json_normalize(station))\n",
    "\n",
    "        # Concatenate all flattened data into a single DataFrame\n",
    "        df = pd.concat(flattened_data, ignore_index=True)\n",
    "\n",
    "        # Save station data to a CSV file\n",
    "        df.to_csv(STATIONS_PATH, index=False)\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    urls = [\n",
    "        f\"{API_BASE_URL}/networks\",\n",
    "        f\"{API_BASE_URL}/networks/{NETWORK_ID}\"\n",
    "    ]\n",
    "\n",
    "    for url in urls:\n",
    "        print(f\"Fetching data from {url}\")\n",
    "        data = fetch_json_data(url)\n",
    "\n",
    "        if url == f\"{API_BASE_URL}/networks\":\n",
    "            process_network_data(data)\n",
    "        elif url == f\"{API_BASE_URL}/networks/{NETWORK_ID}\":\n",
    "            process_station_data(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the details you want for the bike stations in that city (latitude, longitude, number of bikes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stations_data(url):\n",
    "    \"\"\"Fetch data from API and return JSON.\"\"\"\n",
    "    try:\n",
    "        with requests.Session() as session:\n",
    "            response = session.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_stations_data(stations_data):\n",
    "    \"\"\"Parse stations data from JSON.\"\"\"\n",
    "    if not stations_data:\n",
    "        return []\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"name\": station['name'],\n",
    "            \"latitude\": station['latitude'],\n",
    "            \"longitude\": station['longitude'],\n",
    "            \"free_bikes\": station['free_bikes'],\n",
    "            \"empty_slots\": station['empty_slots'],\n",
    "            \"total_bikes\": station['empty_slots'] + station['free_bikes'],\n",
    "            \"usage_percentage\": (\n",
    "                station['empty_slots'] / (station['empty_slots'] + station['free_bikes'])\n",
    "                if (station['empty_slots'] + station['free_bikes']) != 0 else 0\n",
    "            )\n",
    "        } for station in stations_data.get('network', {}).get('stations', [])\n",
    "    ]\n",
    "\n",
    "# Usage\n",
    "stations_url = \"http://api.citybik.es/v2/networks/velib\"\n",
    "stations_raw_data = get_stations_data(stations_url)\n",
    "stations_parsed_data = parse_stations_data(stations_raw_data)\n",
    "\n",
    "# Now stations_parsed_data contains the structured data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame creation\n",
    "stations_df = pd.DataFrame(stations_parsed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter stations based on API limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define broader latitude and longitude bounds\n",
    "lat_min, lat_max = 48.85, 48.88  # Broader range for latitude to include both landmarks\n",
    "lon_min, lon_max = 2.29, 2.35    # Broader range for longitude to include both landmarks\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame with 'latitude' and 'longitude' columns\n",
    "\n",
    "# Filter the DataFrame based on the defined bounds\n",
    "filtered_df = stations_df[(stations_df['latitude'] >= lat_min) & (stations_df['latitude'] <= lat_max) &\n",
    "                 (stations_df['longitude'] >= lon_min) & (stations_df['longitude'] <= lon_max)]\n",
    "\n",
    "# Proceed with further processing on filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered by Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central point (Notre-Dame Cathedral)\n",
    "center_lat, center_lon = 48.8606, 2.3376  # Coordinates of the Louvre\n",
    "\n",
    "\n",
    "# Degree changes for 2 km radius\n",
    "radius_lat = 0.015  # Approximate radius in degrees latitude\n",
    "radius_lon = 0.020  # Approximate radius in degrees longitude\n",
    "\n",
    "# Calculate new bounds\n",
    "lat_min = center_lat - radius_lat\n",
    "lat_max = center_lat + radius_lat\n",
    "lon_min = center_lon - radius_lon\n",
    "lon_max = center_lon + radius_lon\n",
    "\n",
    "# Assuming df is your DataFrame with 'latitude' and 'longitude' columns\n",
    "\n",
    "# Filter the DataFrame based on the defined bounds\n",
    "filtered_df = stations_df[(stations_df['latitude'] >= lat_min) & (stations_df['latitude'] <= lat_max) &\n",
    "                 (stations_df['longitude'] >= lon_min) & (stations_df['longitude'] <= lon_max)]\n",
    "\n",
    "# Proceed with further processing on filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df.to_csv('../data/stations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stations_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking data integrity and data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stations_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning. Checking for duplicates and Null Values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stations_df.duplicated().sum())\n",
    "print(stations_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create a map centered around the approximate center of the expanded bounds\n",
    "map_center = [(lat_min + lat_max) / 2, (lon_min + lon_max) / 2]\n",
    "map_folium = folium.Map(location=map_center, zoom_start=14)\n",
    "\n",
    "# Adding markers for each bike station in the filtered DataFrame\n",
    "for index, row in stations_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=row['name'],\n",
    "        icon=folium.Icon(icon='bicycle', color='blue')\n",
    "    ).add_to(map_folium)\n",
    "\n",
    "# Display the map\n",
    "map_folium\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactice Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Function to fetch and filter data\n",
    "def search_bike_networks(query):\n",
    "    url = \"http://api.citybik.es/v2/networks\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an exception for non-200 status codes\n",
    "\n",
    "    networks = response.json()['networks']\n",
    "\n",
    "    query = query.lower()\n",
    "    filtered_networks = [\n",
    "        network for network in networks\n",
    "        if query in network['location']['city'].lower() or\n",
    "           query in network['location']['country'].lower() or\n",
    "           query in network['id'].lower()\n",
    "    ]\n",
    "\n",
    "    return filtered_networks\n",
    "\n",
    "# Get user input and display results\n",
    "query_input = input(\"Enter city, country code, or company ID: \").strip()\n",
    "\n",
    "if query_input:\n",
    "    search_results = search_bike_networks(query_input)\n",
    "\n",
    "    # Print the total number of results\n",
    "    total_results = len(search_results)\n",
    "    print(f\"Total number of results for '{query_input}': {total_results}\")\n",
    "\n",
    "    # Print the filtered results\n",
    "    for network in search_results:\n",
    "        print(f\"Network ID: {network['id']}\")\n",
    "        location = f\"{network['location']['city']}, {network['location']['country']}\"\n",
    "        print(f\"Location: {location}\")\n",
    "        companies = ', '.join(network['company'])\n",
    "        print(f\"Company: {companies}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No query provided.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
